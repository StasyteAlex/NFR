{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdf2a6f-fd6a-4384-85db-f4c57ad99f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "#import re\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from openpyxl import load_workbook\n",
    "import warnings\n",
    "import pathlib \n",
    "from pathlib import Path \n",
    "import threading\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='openpyxl')\n",
    "\n",
    "# MANUAL input to change\n",
    "your_ing_id = \"XO21BM\"\n",
    "date = datetime.strptime('2024', \"%Y\")\n",
    "update_final_overview = True\n",
    "\n",
    "# DO NOT CHANGE ANYTHING BELOW - only when developing code\n",
    "# determining operating system\n",
    "is_windows = os.name == 'nt'\n",
    "if is_windows:\n",
    "    base_dir = os.path.join(\"C:\", \"\\\\Users\", your_ing_id, \"ING\")\n",
    "else:\n",
    "    base_dir = pathlib.Path(f\"/Users/{your_ing_id}/Library/CloudStorage/OneDrive-SharedLibraries-ING\")\n",
    "\n",
    "# Define paths dynamically\n",
    "directory_path0 = os.getcwd()\n",
    "directory_path = os.path.join(base_dir, \"Product Evaluation and Risk Assessment Library (PEARL) - PEARL_Repository\")\n",
    "directory_path2 = os.path.join(base_dir, \"Product Evaluation and Risk Assessment Library (PEARL) - MI Dashboard\")\n",
    "directory_path3 = os.path.join(directory_path0, \"Intermediate results\")\n",
    "final_overview = pd.read_csv('final_overview.csv', sep=';')\n",
    "\n",
    "# Print paths\n",
    "print(f\"Operating System: {'Windows' if is_windows else 'Mac/Linux'}\")\n",
    "print(f\"PEARL Repository Path: {directory_path}\")\n",
    "print(f\"MI Dashboard Path: {directory_path2}\")\n",
    "print(f\"Intermediate Results Path: {directory_path3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5930136b-adc9-41e8-8a60-0b0a93984c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DataFrames\n",
    "dt1, dt2, dt3, dt4, dt5, dt6, dt7 = [pd.DataFrame() for _ in range(7)]\n",
    "\n",
    "# Check if directory is empty\n",
    "all_files = os.listdir(directory_path3)\n",
    "if not all_files:\n",
    "    raise ValueError(\"Error: directory_path3 is empty!\")\n",
    "\n",
    "# Process files\n",
    "for f in tqdm(all_files):\n",
    "    file_path = os.path.join(directory_path3, f)\n",
    "\n",
    "    # Ensure it's a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        try:\n",
    "            dt_f = pd.read_csv(file_path, sep=';', encoding='utf-8')\n",
    "            if 'process_module_selection' in f:\n",
    "                dt1 = pd.concat([dt1, dt_f])\n",
    "            elif 'risk_summary_approval' in f:\n",
    "                dt2 = pd.concat([dt2, dt_f])\n",
    "            elif 'general_risk_ident_1' in f:\n",
    "                dt3 = pd.concat([dt3, dt_f])\n",
    "            elif 'general_risk_ident_2' in f:\n",
    "                dt4 = pd.concat([dt4, dt_f])\n",
    "            elif 'module_selected' in f:\n",
    "                dt5 = pd.concat([dt5, dt_f])\n",
    "            elif 'assesment_stage' in f:\n",
    "                dt6 = pd.concat([dt6, dt_f])\n",
    "            elif 'journey_summary' in f:\n",
    "                dt7 = pd.concat([dt7, dt_f])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {f}: {e}\")\n",
    "\n",
    "# Create backup copies before modification\n",
    "dataframes = [dt1, dt2, dt3, dt4, dt5, dt6, dt7]\n",
    "dataframes_backup = [df.copy() for df in dataframes]\n",
    "\n",
    "# Normalize folder paths (Mac-safe)\n",
    "for i in range(len(dataframes)):\n",
    "    if 'Folder' in dataframes[i].columns:\n",
    "        dataframes[i]['Folder'] = dataframes[i]['Folder'].apply(lambda x: str(Path(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387cc307-32a1-4268-9a24-086421829c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with final overview each \n",
    "dt1 = dt1.merge(final_overview, on=\"Folder\", how=\"left\")\n",
    "dt2 = dt2.merge(final_overview, on=\"Folder\", how=\"left\")\n",
    "dt3 = dt3.merge(final_overview, on=\"Folder\", how=\"left\")\n",
    "dt4 = dt4.merge(final_overview, on=\"Folder\", how=\"left\")\n",
    "dt5 = dt5.merge(final_overview, on=\"Folder\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2977f228-2d04-46e3-959b-eda3ba009e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### data manipulation for each individual df process_module_selection\n",
    "\n",
    "cond = dt1['File'].isna()\n",
    "dt1.loc[cond, \"Missing data\"] = True\n",
    "dt1.loc[~cond, \"Missing data\"] = False\n",
    "\n",
    "cond = (dt1['ORM_check'] == 'ORM') & (dt1['IRM_check'] == 'IRM')\n",
    "dt1.loc[cond, \"Data correct\"] = True  \n",
    "dt1.loc[~cond, \"Data correct\"] = False  \n",
    "\n",
    "cond = (dt1['IRM'] == 'Yes')\n",
    "dt1.loc[cond, 'IRM'] = '1'\n",
    "dt1.loc[~cond, 'IRM'] = '0'\n",
    "\n",
    "dt1['IRM'] = pd.to_numeric(dt1['IRM'], errors='coerce')\n",
    "\n",
    "cond = (dt1['ORM'] == 'Yes')\n",
    "dt1.loc[cond, 'ORM'] = '1'\n",
    "dt1.loc[~cond, 'ORM'] = '0'\n",
    "\n",
    "dt1['ORM'] = pd.to_numeric(dt1['ORM'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334f8e51-c99e-49b1-bd9c-eca69d3f928d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IRM & ORM dt2 risk summary approval \n",
    "cond = dt2['File'].isna()\n",
    "dt2.loc[cond, 'Missing data'] = True\n",
    "dt2.loc[~cond, 'Missing data'] = False\n",
    "\n",
    "cond = (dt2['ORM_check'] == 'ORM') & (dt2['IRM_check'] == 'IRM')\n",
    "dt2.loc[cond, 'Data correct'] = True\n",
    "dt2.loc[~cond, 'Data correct'] = False\n",
    "\n",
    "cond = (dt2['ORM_invited_or_challange'] == 'To be invited for challenge')\n",
    "dt2.loc[cond, 'ORM_invited_or_challange'] = '1'\n",
    "dt2.loc[~cond, 'ORM_invited_or_challange'] = '0'\n",
    "\n",
    "dt2['ORM_invited_or_challange'] = pd.to_numeric(dt2['ORM_invited_or_challange'], errors='coerce')\n",
    "\n",
    "cond = (dt2['IRM_invited_or_challange'] == 'To be informed')\n",
    "dt2.loc[cond, 'IRM_invited_or_challange'] = '1'\n",
    "dt2.loc[~cond, 'IRM_invited_or_challange'] = '0'\n",
    "\n",
    "dt2['IRM_invited_or_challange'] = pd.to_numeric(dt2['IRM_invited_or_challange'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eda00e-1296-4104-ae65-8094ee2b24b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general_risk_ident_1\n",
    "cond = dt3['File'].isna()\n",
    "dt3.loc[cond, 'Missing data'] = True\n",
    "dt3.loc[~cond, 'Missing data'] = False\n",
    "\n",
    "cond = (dt3['ORM_check'] == 'ORM') & (dt3['IRM_check'] == 'IRM')\n",
    "dt3.loc[cond, 'Data correct'] = True\n",
    "dt3.loc[~cond, 'Data correct'] = False\n",
    "\n",
    "cond = (dt3['ORM_invited'] == 'Yes')\n",
    "dt3.loc[cond, 'ORM_invited'] = '1'\n",
    "dt3.loc[~cond, 'ORM_invited'] = '0'\n",
    "\n",
    "dt3['ORM_invited'] = pd.to_numeric(dt3['ORM_invited'], errors='coerce')\n",
    "\n",
    "cond = (dt3['IRM_invited'] == 'Yes')\n",
    "dt3.loc[cond, 'IRM_invited'] = '1'\n",
    "dt3.loc[~cond, 'IRM_invited'] = '0'\n",
    "\n",
    "dt3['IRM_invited'] = pd.to_numeric(dt3['IRM_invited'], errors='coerce')\n",
    "\n",
    "cond = (dt3['ORM_part_of_risk_asses'] == 'Yes')\n",
    "dt3.loc[cond, 'ORM_part_of_risk_asses'] = '1'\n",
    "dt3.loc[~cond, 'ORM_part_of_risk_asses'] = '0'\n",
    "\n",
    "dt3['ORM_part_of_risk_asses'] = pd.to_numeric(dt3['ORM_part_of_risk_asses'], errors='coerce')\n",
    "\n",
    "cond = (dt3['IRM_part_of_risk_asses'] == 'Yes')\n",
    "dt3.loc[cond, 'IRM_part_of_risk_asses'] = '1'\n",
    "dt3.loc[~cond, 'IRM_part_of_risk_asses'] = '0'\n",
    "\n",
    "dt3['IRM_part_of_risk_asses'] = pd.to_numeric(dt3['IRM_part_of_risk_asses'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a61c4d7-186e-45b8-843d-e563a08dbeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general_risk_ident_2\n",
    "cond = dt4['File'].isna()\n",
    "dt4.loc[cond, 'Missing data'] = True\n",
    "dt4.loc[~cond, 'Missing data'] = False\n",
    "\n",
    "cond = (dt4['ORM_check'] == 'ORM') & (dt4['IRM_check'] == 'IRM')\n",
    "dt4.loc[cond, 'Data correct'] = True\n",
    "dt4.loc[~cond, 'Data correct'] = False\n",
    "\n",
    "cond = (dt4['ORM_person'] == 'Not applicable')\n",
    "dt4.loc[cond, 'ORM_person'] = '0'\n",
    "dt4.loc[~cond, 'ORM_person'] = '1'\n",
    "\n",
    "dt4['ORM_person'] = pd.to_numeric(dt4['ORM_person'], errors='coerce')\n",
    "\n",
    "cond = (dt4['IRM_person'] == 'Not applicable')\n",
    "dt4.loc[cond, 'IRM_person'] = '0'\n",
    "dt4.loc[~cond, 'IRM_person'] = '1'\n",
    "\n",
    "dt4['IRM_person'] = pd.to_numeric(dt4['IRM_person'], errors='coerce')\n",
    "\n",
    "cond = (dt4['ORM_opinion'] == 'Not applicable')\n",
    "dt4.loc[cond, 'ORM_opinion'] = '0'\n",
    "dt4.loc[~cond, 'ORM_opinion'] = '1'\n",
    "\n",
    "dt4['ORM_opinion'] = pd.to_numeric(dt4['ORM_opinion'], errors='coerce')\n",
    "\n",
    "cond = (dt4['IRM_opinion'] == 'Not applicable')\n",
    "dt4.loc[cond, 'IRM_opinion'] = '0'\n",
    "dt4.loc[~cond, 'IRM_opinion'] = '1'\n",
    "\n",
    "dt4['IRM_opinion'] = pd.to_numeric(dt4['IRM_opinion'], errors='coerce')\n",
    "\n",
    "cond = (dt4['ORM_challenge'] == 'Not applicable')\n",
    "dt4.loc[cond, 'ORM_challenge'] = '0'\n",
    "dt4.loc[~cond, 'ORM_challenge'] = '1'\n",
    "\n",
    "dt4['ORM_challenge'] = pd.to_numeric(dt4['ORM_challenge'], errors='coerce')\n",
    "\n",
    "cond = (dt4['IRM_challenge'] == 'Not applicable')\n",
    "dt4.loc[cond, 'IRM_challenge'] = '0'\n",
    "dt4.loc[~cond, 'IRM_challenge'] = '1'\n",
    "\n",
    "dt4['IRM_challenge'] = pd.to_numeric(dt4['IRM_challenge'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b21155-5bdb-4b00-8194-27d64653c6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt1['End Date'] = dt1['End Date'].fillna(pd.Timestamp(datetime.today().date()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f36a7a3-7508-4377-93b3-2113eee06a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "### first data analysis dt1 used for the main reporting in performance wall\n",
    "### creating categories to report days open \n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# dt1\n",
    "dt1['Start Date'] = pd.to_datetime(dt1['Start Date'])\n",
    "dt1[\"End Date\"] = pd.to_datetime(dt1[\"End Date\"])  \n",
    "dt1[\"Year\"] = dt1[\"End Date\"].dt.year\n",
    "dt1[\"Quarter\"] = dt1[\"End Date\"].dt.to_period(\"Q\")\n",
    "dt1[\"Quarter\"] = dt1[\"Quarter\"].fillna(\"Unknown\").astype(str)\n",
    "dt1[\"Quarter\"] = dt1[\"End Date\"].dt.to_period(\"Q\").astype(str)\n",
    "\n",
    "dt1[\"YTD\"] = datetime.today().date()\n",
    "\n",
    "\n",
    "dt1[\"End Date\"] = dt1[\"End Date\"].fillna(pd.Timestamp(datetime.today().date()))\n",
    "dt1[\"No_End_date\"] = dt1[\"End Date\"] == dt1[\"YTD\"]\n",
    "\n",
    "# calculate duration\n",
    "dt1[\"Duration\"] = (dt1[\"End Date\"] - dt1[\"Start Date\"]).dt.days\n",
    "dt1[\"Duration\"] = pd.to_numeric(dt1[\"Duration\"], errors='coerce')\n",
    "\n",
    "# create categories\n",
    "def categorize_days(x):\n",
    "    if x < 30:\n",
    "        return \"<30 days\"\n",
    "    elif x < 60:\n",
    "        return \"30-60 days\"\n",
    "    elif x < 90:\n",
    "        return \"60-90 days\"\n",
    "    elif x < 120:\n",
    "        return \"90-120 days\"\n",
    "    elif x < 180:\n",
    "        return \"120-180 days\"\n",
    "    else:\n",
    "        return \">180 days\"\n",
    "\n",
    "dt1['Category'] = dt1['Duration'].apply(categorize_days)\n",
    "\n",
    "# just to check categorisation\n",
    "#count_table = dt1['Category'].value_counts().reset_index()\n",
    "#count_table.columns = ['Unique Value', 'Count']\n",
    "#print(count_table)\n",
    "\n",
    "# Final filter fot dt1\n",
    "filtered_data = dt1[dt1[\"Process Category\"].isin([\"Risk assessment (non-PAP)\", \"Other change (non-PAP)\"])]\n",
    "\n",
    "# filter_data is also input continued analysis on dt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122d91c7-5cdb-4980-8fc8-fe4ddf07978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PAP output same output, but filtered on non PAP\n",
    "filtered_data_PAP = dt1[dt1[\"Process Category\"].isin([\"New financial product/-service/channel (PAP)\", \"Significant change financial product/-service/channel (PAP) \", \"Termination of financial product/-service/channel (PAP)\"])]\n",
    "#filtered_data_PAP\n",
    "\n",
    "dt1_grouped_PAP = filtered_data_PAP.groupby(['Missing data', \n",
    "                           'Data correct', \n",
    "                           'Type',\n",
    "                           'Quarter']).agg({'ORM': 'sum', \n",
    "                                       'IRM': 'sum', \n",
    "                                       'Folder': 'count'})\n",
    "#dt1_grouped_PAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2428d7-e2fe-4000-ac0e-315f141265a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### pivot for overall dt1 output \n",
    "dt1_grouped = filtered_data.groupby(['Missing data', \n",
    "                           'Data correct', \n",
    "                           'Type',\n",
    "                           'Quarter']).agg({'ORM': 'sum', \n",
    "                                       'IRM': 'sum', \n",
    "                                       'Folder': 'count'})\n",
    "#dt1_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72a9516-4c21-4719-8e9e-07c725a1b255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create percentages\n",
    "dt1_percent = dt1_grouped.copy()\n",
    "\n",
    "# Divide ORM & IRM by total Folder count per quarter\n",
    "cols_to_percent = [\"ORM\", \"IRM\"]\n",
    "dt1_percent[cols_to_percent] = dt1_percent[cols_to_percent].div(\n",
    "    dt1_percent[\"Folder\"], axis=0) * 100\n",
    "dt1_percent[cols_to_percent] = dt1_percent[cols_to_percent].round(2)\n",
    "#dt1_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae38e6f-e001-4afd-acb7-179e80df3d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### first data analysis for dt2 to report # invited_challenges\n",
    "\n",
    "# dt2\n",
    "dt2[\"End Date\"] = pd.to_datetime(dt2[\"End Date\"])  # Convert to datetime\n",
    "dt2[\"Year\"] = dt2[\"End Date\"].dt.year\n",
    "dt2[\"Quarter\"] = dt2[\"End Date\"].dt.to_period(\"Q\")\n",
    "dt2[\"Quarter\"] = dt2[\"Quarter\"].fillna(\"Unknown\").astype(str)\n",
    "dt2[\"Quarter\"] = dt2[\"End Date\"].dt.to_period(\"Q\").astype(str)\n",
    "\n",
    "#filtered_data = dt2[dt2[\"Process Category\"].isin([\"Risk assessment (non-PAP)\", \"Other change (non-PAP)\"])]\n",
    "\n",
    "dt2_grouped = dt2.groupby(['Missing data', \n",
    "                           'Data correct', \n",
    "                           'Quarter']).agg({'ORM_invited_or_challange': 'sum', \n",
    "                                       'IRM_invited_or_challange': 'sum', \n",
    "                                       'Folder': 'count'})\n",
    "\n",
    "# for dt2: left out the filter on process category as its empty in almost all caes\n",
    "#dt2_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77a7b9b-f8c3-48d8-931e-b7d6b3dd1875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create percentages\n",
    "dt2_percent = dt2_grouped.copy()\n",
    "\n",
    "# Divide ORM & IRM by total Folder count per quarter\n",
    "cols_to_percent = [\"ORM_invited_or_challange\", \"IRM_invited_or_challange\"]\n",
    "dt2_percent[cols_to_percent] = dt2_percent[cols_to_percent].div(\n",
    "    dt2_percent[\"Folder\"], axis=0) * 100\n",
    "dt2_percent[cols_to_percent] = dt2_percent[cols_to_percent].round(2)\n",
    "#dt2_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8516e5f4-041d-429d-a1e7-6edab1cc24d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### first data analysis for dt3\n",
    "\n",
    "# dt3\n",
    "dt3[\"End Date\"] = pd.to_datetime(dt3[\"End Date\"])  # Convert to datetime\n",
    "dt3[\"Year\"] = dt3[\"End Date\"].dt.year\n",
    "\n",
    "dt3[\"Quarter\"] = dt3[\"End Date\"].dt.to_period(\"Q\")\n",
    "dt3[\"Quarter\"] = dt3[\"Quarter\"].fillna(\"Unknown\").astype(str)\n",
    "dt3[\"Quarter\"] = dt3[\"End Date\"].dt.to_period(\"Q\").astype(str)\n",
    "\n",
    "filtered_data = dt3[dt3[\"Process Category\"].isin([\"Risk assessment (non-PAP)\", \"Other change (non-PAP)\"])]\n",
    "\n",
    "\n",
    "dt3_grouped = filtered_data.groupby(['Missing data', \n",
    "                           'Data correct', \n",
    "                           'Quarter']).agg({'ORM_invited': 'sum', \n",
    "                                         'IRM_invited': 'sum',    \n",
    "                                         'ORM_part_of_risk_asses': 'sum', \n",
    "                                         'IRM_part_of_risk_asses': 'sum', \n",
    "                                         'Folder': 'count'})\n",
    "#dt3_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0997512a-5db7-4c84-bbbb-1d7163647a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create percentages\n",
    "dt3_percent = dt3_grouped.copy()\n",
    "\n",
    "# Divide ORM & IRM by total Folder count per quarter\n",
    "cols_to_percent = [\"ORM_invited\", \"IRM_invited\", \"ORM_part_of_risk_asses\", \"IRM_part_of_risk_asses\"]\n",
    "dt3_percent[cols_to_percent] = dt3_percent[cols_to_percent].div(\n",
    "    dt3_percent[\"Folder\"], axis=0) * 100\n",
    "dt3_percent[cols_to_percent] = dt3_percent[cols_to_percent].round(2)\n",
    "#dt3_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90daa72e-4d89-4ef8-9f77-b733a2189abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### first data analysis dt4\n",
    " \n",
    "# dt4\n",
    "dt4[\"End Date\"] = pd.to_datetime(dt4[\"End Date\"])  # Convert to datetime\n",
    "dt4[\"Year\"] = dt4[\"End Date\"].dt.year\n",
    "\n",
    "dt4[\"Quarter\"] = dt4[\"End Date\"].dt.to_period(\"Q\")\n",
    "dt4[\"Quarter\"] = dt4[\"Quarter\"].fillna(\"Unknown\").astype(str)\n",
    "dt4[\"Quarter\"] = dt4[\"End Date\"].dt.to_period(\"Q\").astype(str)\n",
    "\n",
    "filtered_data = dt4[dt4[\"Process Category\"].isin([\"Risk assessment (non-PAP)\", \"Other change (non-PAP)\"])]\n",
    "\n",
    "\n",
    "dt4_grouped = filtered_data.groupby(['Missing data', \n",
    "                           'Data correct', \n",
    "                           'Quarter']).agg({'ORM_person': 'sum', \n",
    "                                         'IRM_person': 'sum',    \n",
    "                                         'ORM_opinion': 'sum', \n",
    "                                         'IRM_opinion': 'sum',\n",
    "                                         'ORM_challenge': 'sum', \n",
    "                                         'IRM_challenge': 'sum', \n",
    "                                         'Folder': 'count'})\n",
    "\n",
    "#dt4_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4e4f13-6fdd-43a5-b4a2-033897a880f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create percentages\n",
    "dt4_percent = dt4_grouped.copy()\n",
    "\n",
    "# Divide ORM & IRM by total Folder count per quarter\n",
    "cols_to_percent = [\"ORM_person\", \"IRM_person\", \"ORM_opinion\", \"IRM_opinion\", \"ORM_challenge\", \"IRM_challenge\"]\n",
    "dt4_percent[cols_to_percent] = dt4_percent[cols_to_percent].div(\n",
    "    dt4_percent[\"Folder\"], axis=0) * 100\n",
    "dt4_percent[cols_to_percent] = dt4_percent[cols_to_percent].round(2)\n",
    "#dt4_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19f175e-027b-4a30-a0a4-f699a96992ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### module_selected\n",
    "\n",
    "dt5[\"End Date\"] = pd.to_datetime(dt5[\"End Date\"], errors=\"coerce\")  \n",
    "dt5[\"Year\"] = dt5[\"End Date\"].dt.year  \n",
    "dt5[\"Quarter\"] = dt5[\"End Date\"].dt.to_period(\"Q\")\n",
    "dt5[\"Quarter\"] = dt5[\"Quarter\"].fillna(\"Unknown\").astype(str)\n",
    "dt5[\"Quarter\"] = dt5[\"End Date\"].dt.to_period(\"Q\").astype(str)\n",
    "\n",
    "# add column with sum # modules selected\n",
    "df_5_module_selected =dt5.groupby([\"Folder\", \n",
    "                                    \"File\",\n",
    "                                    \"Quarter\"]).agg({\n",
    "    \"Applicable\": lambda x: x.sum()  \n",
    "}).reset_index()\n",
    "\n",
    "df_5_module_selected.rename(columns={\"Applicable\": \"Applicable_modules_selected\"}, inplace=True)\n",
    "df_5_module_selected[\"Quarter\"] = df_5_module_selected[\"Quarter\"].astype(str)\n",
    "\n",
    "### dt7 -> needs to do the same with this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14a7a25-c3a4-47c9-9481-50dff10eb48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### first data analysis dt5 with # modules selected\n",
    "df_wide = df_5_module_selected.pivot_table(index=\"Quarter\", \n",
    "                                           columns=\"Applicable_modules_selected\", \n",
    "                                           values=\"File\", \n",
    "                                           aggfunc=\"count\").fillna(0)\n",
    "\n",
    "# Reset index to make it cleaner\n",
    "df_wide.reset_index(inplace=True)\n",
    "#df_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d3bdf7-1938-45dd-b5a2-21848066a1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_percent = df_wide.copy()  \n",
    "module_cols = df_percent.columns.difference([\"Quarter\"])\n",
    "df_percent[module_cols] = df_percent[module_cols].div(df_percent[module_cols].sum(axis=1), axis=0) * 100\n",
    "df_percent[module_cols] = df_percent[module_cols].round(2)\n",
    "#df_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68d4837-dcac-4f1b-b64d-ffa59c562533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the manipulated versions \n",
    "\n",
    "dt1.to_csv(\"dt1.csv\", index=False)\n",
    "dt2.to_csv(\"dt2.csv\", index=False)\n",
    "dt3.to_csv(\"dt3.csv\", index=False)\n",
    "dt4.to_csv(\"dt4.csv\", index=False)\n",
    "df_5_module_selected.to_csv(\"df_5_module_selected.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bcf158-6951-4f15-bcc3-7ead672aa3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table with duraction RA's per category Richards request\n",
    "\n",
    "dt1_grouped1 = filtered_data.groupby(['Missing data', \n",
    "                           'Data correct', \n",
    "                           'Type',\n",
    "                           'Category',\n",
    "                           'Quarter']).agg({#'Category': 'count', \n",
    "                                       'Folder': 'count'})\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "category_order = [\"<30 days\", \"30-60 days\", \"60-90 days\", \"90-120 days\", \"120-180 days\", \">180 days\"]\n",
    "dt1_grouped1 = dt1_grouped1.reset_index()\n",
    "dt1_grouped1['Category'] = pd.Categorical(dt1_grouped1['Category'], categories=category_order, ordered=True)\n",
    "dt1_grouped1 = dt1_grouped1.sort_values(by='Category')\n",
    "#dt1_grouped1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589434f2-1e69-4932-828b-1f088610ffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## pivot duration categories * quarters\n",
    "dt1_pivoted = dt1_grouped1.pivot_table(\n",
    "    index=['Missing data', 'Data correct', 'Type', 'Category'],\n",
    "    columns='Quarter',\n",
    "    values=['Category', 'Folder'],  \n",
    "    fill_value=0  \n",
    ")\n",
    "#dt1_pivoted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8739949-4a9c-4ef3-915d-2b179b3abdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the same for the ones still open, Richards request\n",
    "\n",
    "filtered_dt1 =filtered_data[filtered_data[\"No_End_date\"] == True]\n",
    "\n",
    "dt1_grouped2 = filtered_dt1.groupby(['Missing data', \n",
    "                           'Data correct', \n",
    "                           'Type',\n",
    "                           'No_End_date',\n",
    "                           'Category',\n",
    "                           'Quarter']).agg({#'Category': 'count', \n",
    "                                       'Folder': 'count'})\n",
    "\n",
    "dt1_grouped2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "category_order = [\"<30 days\", \"30-60 days\", \"60-90 days\", \"90-120 days\", \"120-180 days\", \">180 days\"]\n",
    "dt1_grouped2 = dt1_grouped2.reset_index()\n",
    "dt1_grouped2['Category'] = pd.Categorical(dt1_grouped2['Category'], categories=category_order, ordered=True)\n",
    "dt1_grouped2 = dt1_grouped2.sort_values(by='Category')\n",
    "dt1_grouped2\n",
    "\n",
    "dt1_pivoted2 = dt1_grouped2.pivot_table(\n",
    "    index=['Missing data', 'Data correct', 'Type', 'Category'],\n",
    "    columns='Quarter',\n",
    "    values=['Category', 'Folder'],  \n",
    "    fill_value=0  \n",
    ")\n",
    "#dt1_pivoted2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75741b3-111e-479a-a79c-c6e120cea445",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_dt1\n",
    "filtered_dt1.to_csv(\"filtered_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3fcce3-a0fe-4b02-8900-1e17167bfcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## analysis duration in days average per tribe to see whether there are some tribes with more duration. Results do not show very clear differences\n",
    "\n",
    "filtered_data = dt1[dt1[\"Process Category\"].isin([\"Risk assessment (non-PAP)\", \"Other change (non-PAP)\"])]\n",
    "\n",
    "dt1_grouped2 = filtered_data.groupby(['Missing data', \n",
    "                           'Data correct', \n",
    "                           'Type',\n",
    "                           'Tribe',\n",
    "                           'Quarter']).agg({'Duration': 'mean', \n",
    "                                       'Folder': 'count'})\n",
    "#dt1_grouped2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7127597d-9506-4a52-a560-ff82384e2312",
   "metadata": {},
   "outputs": [],
   "source": [
    "## analysis duration in days average per tribe pivot\n",
    "\n",
    "dt1_pivoted2 = dt1_grouped2.pivot_table(\n",
    "    index=['Missing data', 'Data correct', 'Type', 'Tribe'],\n",
    "    columns=['Quarter'],  \n",
    "    values=['Duration'],  \n",
    "    fill_value=0  \n",
    ")\n",
    "#dt1_pivoted2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e4bde7-bf99-4022-963a-0a8a46c22b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## to interrpet the means duration get totals per tribe \n",
    "\n",
    "filtered_data = dt1[dt1[\"Process Category\"].isin([\"Risk assessment (non-PAP)\", \"Other change (non-PAP)\"])]\n",
    "\n",
    "dt1_grouped3 = filtered_data.groupby(['Missing data', \n",
    "                           'Data correct', \n",
    "                           'Type',\n",
    "                           'Tribe',\n",
    "                           'Quarter']).agg({\n",
    "                                       'Folder': 'count'})\n",
    "#dt1_grouped3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8defa1-e3e9-4234-9f62-8c403b01bbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## to interrpet the means duration get totals per tribe \n",
    "dt1_pivoted3 = dt1_grouped3.pivot_table(\n",
    "    index=['Missing data', 'Data correct', 'Type', 'Tribe'],\n",
    "    columns=['Quarter'],  \n",
    "    values=['Folder'],  \n",
    "    fill_value=0  \n",
    ")\n",
    "#dt1_pivoted3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ce7e3c-05ec-4db6-a5c8-be76a3ec6eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## trying to connect dt3 & dt4 to have the information from sheet risk_identification in one file\n",
    "\n",
    "import pandas as pd\n",
    "merged_df = pd.merge(dt3, dt4, on=['Folder', 'File'], how='inner', suffixes=('', '_dup'))\n",
    "merged_df = merged_df.loc[:, ~merged_df.columns.str.endswith('_dup')]\n",
    "\n",
    "merged_df\n",
    "merged_df2 = merged_df[merged_df[\"Process Category\"].isin([\"Risk assessment (non-PAP)\", \"Other change (non-PAP)\"])]\n",
    "merged_df_pivot = merged_df2.groupby(['Missing data', \n",
    "                           'Data correct', \n",
    "                          # 'Type',\n",
    "                           'ORM_invited',\n",
    "                           'IRM_invited',\n",
    "                           'ORM_part_of_risk_asses',\n",
    "                           'IRM_part_of_risk_asses', \n",
    "                           'ORM_person',\n",
    "                           'IRM_person',\n",
    "                           #'Quarter'\n",
    "                                     ]).agg({\n",
    "                                       'Folder': 'count'})\n",
    "\n",
    "merged_df_pivot\n",
    "\n",
    "### does not really add up to something meaningful. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
